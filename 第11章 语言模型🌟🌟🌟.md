# 1 语言模型基础🌟🌟

学习目标：*本节主要介绍语言模型相关的基础，如什么是语言模型、为什么需要语言模型、以及语言模型的不同种类。*

相关知识点：

*语言模型*

## PART1: 什么是语言模型

### Language Model (LM)

语言模型是一个非常重要的概念，用一句通俗的非官方的话来解释语言模型，就是：从语法上判断一句话是否通顺。

机器翻译模型逐词翻译过来的句子可能不通顺，这时候就需要语言模型来判断。

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810075046767.png" alt="image-20210810075046767" style="zoom:33%;" />

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810075202015.png" alt="image-20210810075202015" style="zoom:33%;" />

“总结起来的话，语言模型最主要的作用是保证文本的语法结构，得到通顺的语句。语言模型是一种概率统计的方法，已经训练好的语言模型可以对任何一个文本给出概率，概率越高说明语法上越通顺。通过比较两句话在同一个语言模型上的概率，我们就可以得出哪一句话更通顺一些。”

### 练习

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810075341558.png" alt="image-20210810075341558" style="zoom:33%;" />

## PART2: 计算语言模型的概率

### Language Model

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810075613661.png" alt="image-20210810075613661" style="zoom:33%;" />

### 练习

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810075857302.png" alt="image-20210810075857302" style="zoom:30%;" />

### Recap: Chain Rule

联合分布（相互独立或不独立）可以表示成各项条件概率x相乘的形式

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810080324590.png" alt="image-20210810080324590" style="zoom:33%;" />

### Chain Rule for Language Model

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810081020455.png" alt="image-20210810081020455" style="zoom:33%;" />

### 练习

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810081205664.png" alt="image-20210810081205664" style="zoom:33%;" />

## PART3: 马尔科夫假设

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210810081706082.png" alt="image-20210810081706082" style="zoom:33%;" />

Chain Rule for Language Model

Markov Assumption

Language Model (Use 2nd Order)

# 2 语言模型训练🌟🌟🌟

## PART1: 不同的语言模型

### Unigram

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210812073715036.png" alt="image-20210812073715036" style="zoom:33%;" />

### Bigram

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210812073610879.png" alt="image-20210812073610879" style="zoom:33%;" />

Bigram模型会考虑顺序 ，而unigram模型不会

### N-gram

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210812073549412.png" alt="image-20210812073549412" style="zoom:33%;" />

## PART2: 语言模型的训练

### Unigram: Estimating Probability 

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210812080730371.png" alt="image-20210812080730371" style="zoom:33%;" />

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210812080952520.png" alt="image-20210812080952520" style="zoom:33%;" />

单词概率=单词在文档中出现的次数/文档中单词总数

如果一项是0，全部都是0

### Bigram: Estimating Probability 

# 3 语言模型的评估🌟🌟

PART1: 困惑度（perplexity）

# 4 语言模型的平滑🌟🌟🌟

PART1: 训练语言模型时的问题

PART2: Add-one Smoothing

PART3: Add-K Smoothing

PART4: Interpolation