# 一、RNN模型的必要性🌟🌟

## 1. 时间序列数据

### 1.1 CNN模型 - 图像识别

CNN 诞生于图像处理
常见CNN模型：vgg16 vgg19 GoogleNet AlexNet
CNN也可以用在时间序列模型上，但不是最好的选择

### 1.2 为什么需要递归神经网络（RNN）

股价、天气等随时间维度变化的数据，文本也是一种重要的时间序列数据，所以RNN常用于文本分析。

其中，股价和天气是连续型的，文本是离散型的，但是只要一个数据是随时间变化的，都可以使用RNN



## 2. 数据类型

### 2.1 数据类型

- 静态数据 （Static Data)
    - 图片（所以图片使用cnn建模）
    - 信用分析（使用传统机器学习模型）
- 时间序列数据 (Time Series Data)
    分为连续性和离散型
    使用RNN/LSTM分析
- 图数据（Graph Data)
    - 物联网
      GCN,GAT
      Node2Vec
      今年来由于互联网发展，基于图的数据越来越多，带动了GNN的发展
    
      ![image-20210720215833200](/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210720215833200.png)

## 3. RNN的应用

### 3.1 应用：情感分类

- RNN可用于文本分类

这家店装修不错 正面
这家店装修不错，但牛排是过期的 负面

### 3.2 应用：流畅性评价

ppl 流畅度评估指标
今天是周六  ppl:100
是今天周六  ppl:1000

除了这些应用之外，RNN有很多很多有趣的应用，如生成剧本、生成代码等等。基本上对于文本类的应用，RNN均可以作为最经典的基石(backbone)。同时，RNN也可以配合其他的模型来解决一些更复杂的模型如image captioning。

# 二、RNN详解🌟🌟🌟

## 1. RNN细节

### 1.1 递归神经网络

当前节点信息HT由结合上一时间点的信息H(T-1)和当前节点输入XT决定的
最终计算损失函数值看yT 即最后时间点的输出
（很长很长，需要复习）

最初的RNN：Vanilla模型

### 1.2 递归神经网络 vs 隐马尔可夫模型

隐马尔可夫 独热编码
RNN 分布式编码 表示能力比HMM强
一般来说，HMM能解决的问题RNN照样也可以解决。但正式进入大家的视野之前，HMM主宰了时间序列数据的分析任务。
（需要复习）

## 2. 语言模型与RNN

### 2.1 回顾：语言模型

（需要复习）

### 2.2 利用递归神经网络训练语言模型

RNN最重要的应用 文本生成
经过训练之后才可以用于文本生成
为什么要去关注语言模型? 这个必要性我们首先要弄清楚。之后我们会讲到如何用RNN生成文本，这也是RNN最重要的应用之一。比如做机器翻译系统、把一段很长的文字缩短成较短的文字、让AI写程序等等，这些功能实现实际上均要依赖于语言模型。我们一旦训练好语言模型，就可以用它来生成文本。
（需要复习）



# 三、RNN的梯度问题🌟🌟🌟🌟🌟

## 1. 梯度问题

### 1.1 RNN是深度学习模型

CNN是纵向的

RNN是沿着时间维度的深度学习模型

### 1.2 RNN的梯度消失	

RNN的梯度由很多项的乘积构成，如果每一项都小于一，那这个成绩很容易变成0（梯度消失），如果每一项都大于1，那梯度会变得非常大（梯度爆炸）



关于RNN的梯度问题在很多公司的面试中经常被问到，虽然一般不会让你推导，但至少要知道如何回答此问题。实际上，任何的深度学习模型均存在梯度问题，这也是我们从优化的角度需要解决的一个比较棘手的问题。

另外，为了解决RNN的梯度问题，学者们也提出了很多不同的方法如LSTM， 还有像Transformer等等。关于Transformer将在之后的章节中会涉及到。

## 2. 长序列依赖

简单来说，理解文本时需要知道单词和单词之间的依赖关系，但由于梯度问题，RNN模型很难捕获两个离得比较远的单词的关系。除了视频中讲解的例子之外，还有一个大家经常碰到的例子是“小明今天上班很早，比大明一般早了一个多小时，他这么早到是为了准备会议”， 对于这句话，我们需要知道句子中的“他”指向的是小明还是大明，这就需要模型能够较好地捕获依赖关系了。

## 3. Gradient Clipping

对于梯度爆炸来说，可以使用gradient clipping技术来解决。相比梯度爆炸，梯度消失问题其实更具有挑战。那么，梯度消失问题应该如何解决呢?一种常见的解决方法是使用LSTM结构，可以认为是一种升级版的RNN，在RNN的基础上额外加入了一些结构而成。

# 四、LSTM和GRU🌟🌟🌟🌟

## PART1 LSTM的介绍 

### LSTM

lstm和RNN非常类似，主要解决了RNN的梯度消失问题

（笔记在纸上，7.21）

### LSTM用于文本分类

总结起来，有以下几点:

- LSTM是用来解决RNN的梯度问题，起到了有效缓解作用
- LSTM比RNN多出了几个门，用来控制信息的流动
- LSTM的效率要比RNN低，毕竟计算上多出了更多步骤
- LSTM能比RNN捕获更长的依赖关系

## PART2 双向LSTM

既考虑上文又考虑下文

## PART3 GRU

# 五、RNN的变种🌟🌟🌟

## PART1 RNN的不同结构

### RNN的类型

- A classical NN

- B image captioning(图像字幕)

- C 文本分类

- D machine translation/summarization

- E POS tagging/NER

