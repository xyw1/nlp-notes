# 1 文本分析流程与分词🌟🌟	

学习目标：*在本节重点探讨文本分析的经典流程以及几个经典分词算法。*

相关知识点：

*文本分析*



## PART1: 文本分词流程

就像其他的领域有自己的经典流程一样，一个文本分析的项目也有属于自己的流程。虽然每一个NLP项目有所不同，但至于流程来说没有太多本质的区别。这里会涉及到如分词、停用词过滤、文本向量的转化等步骤。在接下来两章中会对每一个做逐一的讲解。

注：顺序不固定，比如清洗可以放在分词之前，去掉无用字符，分词之后也可以做二次清洗，去掉无用单词

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210728234103124.png" alt="image-20210728234103124" style="zoom: 33%;" />

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210728234448725.png" alt="image-20210728234448725" style="zoom:33%;" />

<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210728234627390.png" alt="image-20210728234627390" style="zoom:30%;" />

## PART2: 分词工具的使用



<img src="/Users/yunwanxu/Library/Application Support/typora-user-images/image-20210728234913473.png" alt="image-20210728234913473" style="zoom:50%;" />

jieba最简单，快，轻量级，而且这个库专门使用来做分词的，设计理念简单。

SnowNLP, LTP和HanNLP也可以分词。

绝大多数情况下没有必要自己写分词工具，因为分词是一个比较通用的工具，不管是做文本摘要，还是搭建问答系统，还是做文本分类，分词本身都可以通用。除了一些特殊情况，比如这些工具没有办法满足我们的需求，可以自己写分词工具。



分词是所有工作的第一步，分词的准确性直接影响对后续任务的表现。但分词技术相对比较成熟，也有很多开源的工具可用来做中文或者对其他语言的分词。在这里，结巴分词算是最经典且简单的中文分词工具。下面以结巴分词为例来说明如何使用工具来分词。



```python
# encoding=utf-8
import jieba
# 基于jieba的分词, 结巴词库不包含"贪心学院"关键词
seg_list = jieba.cut("贪心学院专注于人工智能教育", cut_all=False)
print("Default Mode: " + "/ ".join(seg_list))
jieba.add_word("贪心学院") # 加入关键词
seg_list = jieba.cut("贪心学院专注于人工智能教育", cut_all=False)
print("Default Mode: " + "/ ".join(seg_list))
```

Out:

```txt
Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 1.010 seconds.
Prefix dict has been built successfully.
Default Mode: 贪心/ 学院/ 专注/ 于/ 人工智能/ 教育
Default Mode: 贪心学院/ 专注/ 于/ 人工智能/ 教育
```

### 练习

“贪心科技”,“在线”,“教育”。 但如果给定 “在线教育是”,就无法通过上述词典完整切分了。 写一个程序,输入为词典和一段文本,并判断这段文本是否能被切分成功,如果能切分返回True, 否则返回False。

```python
dic = set(["贪心科技", "人工智能", "教育", "在线", "专注于"])
def word_break(str):
    """
    完成此函数,判断str是否能被完整切分
    """
  return False
assert word_break("贪心科技在线教育")==True
assert word_break("在线教育是")==False
assert word_break("")==True
assert word_break("在线教育人工智能")==True
```





## PART3: 最大匹配算法



## PART4: 考虑语义的一种分词方法

# 2 停用词与词的标准🌟🌟🌟

## PART1: 词的过滤

## PART2: 词的标准化

# 3 拼写纠错🌟🌟🌟

## PART1: 拼写纠错与编辑距离

## PART2: 循环词库的问题以及改进方法